# AUTOGENERATED! DO NOT EDIT! File to edit: 01_data_structure.ipynb (unless otherwise specified).

__all__ = ['SeqenceData', 'TargetData', 'Tfms', 'FootSeqTuple', 'FootSeqTransform', 'FootSeqToTensor', 'Pad_Seq',
           'pad_seq']

# Cell

import os
import pickle
import warnings
from random import sample
from typing import List, Tuple

import numpy as np
import pandas as pd
import progressbar
from fastai.tabular.all import *
from fastai.text.all import *
from fastai.vision.all import *
from fastcore.basics import *
from fastcore.foundation import *

from ..plots import plot_actions

SeqenceData = dict[str, pd.DataFrame]
TargetData = dict[str, str]
Tfms = List[Transform]

# Cell


def _nice_time(row) -> str:
    minute = int((row.period_id - 1) * 45 + row.time_seconds // 60)
    second = int(row.time_seconds % 60)
    return f"{minute}m{second}s"


class FootSeqTuple(fastuple):
    def show(self, ctx=None, **kwargs):
        play_sequence, target = self
        play_sequence.dropna(inplace=True)
        play_sequence["nice_time"] = play_sequence.apply(_nice_time, axis=1)
        labels = play_sequence[
            ["nice_time", "type_name", "player_name", "team_name", "result_name"]
        ]

        ctx = plot_actions(
            location=play_sequence[["start_x", "start_y", "end_x", "end_y"]],
            action_type=play_sequence.type_name,
            team=play_sequence.team_name,
            result=play_sequence.result_name,
            label=labels,
            labeltitle=["time", "action", "player", "team", "result"],
            zoom=False,
            ax=ctx,
            show=False,
            **kwargs,
        )
        ctx.set_title(target)

        return ctx

# Cell


class FootSeqTransform(ItemTransform):
    """
    Produce a processed sequence of play and a target
    """
    def __init__(
        self,
        sequence_df: pd.DataFrame,
        target_dict: TargetData,
        ids: List[str],
        splits: List[int],
        labels: List[str],
        procs: Tfms = None,
        cat_names: List[str] = None,
        cont_names: List[str] = None,
        **kwargs
    ):
        ## find the different keys
        self.ids, self.targets, self.cat_names, self.cont_names = (
            ids,
            target_dict,
            cat_names,
            cont_names,
        )

        ## keep only ids passed
        self.raw_seqs = sequence_df[sequence_df["_id"].isin(self.ids)]

        ## map targte labels to integers
        self.target_vocab, self.target_o2i = uniqueify(labels, sort=True, bidir=True)

        ## translate splits in terms of df
        splits_df = (
            L(np.where(self.raw_seqs["_id"].isin(self.ids[splits[0]]))[0].tolist()),
            L(np.where(self.raw_seqs["_id"].isin(self.ids[splits[1]]))[0].tolist()),
        )

        ## tabular pandas
        self.to = TabularPandas(
            df=self.raw_seqs,
            procs=procs,
            cat_names=self.cat_names,
            cont_names=self.cont_names,
            splits=splits_df,
            do_setup=True,
            **kwargs
        )

    def encodes(self, seq_id: str):
        return (
            self.to.items[self.to.items["_id"] == seq_id],
            self.target_o2i[self.targets[seq_id]],
        )

    def decodes(self, x):
        return FootSeqTuple(
            x[0].apply(self.to.decode_row, axis=1), self.target_vocab[x[1]]
        )

# Cell


class FootSeqToTensor(ItemTransform):
    "Transform Tuple of pd.DataFrame and integer to appropriate tensors"
    order = 10

    def __init__(self, cat_names, cont_names, feats_first = True, max_len = None):
        store_attr()

    def encodes(self, x):
        ## keep metadata columns
        df, tgt = x

        ## reduce sequence length is needed
        if (not self.max_len is None) and (type(self.max_len) == int):
            df = df.tail(self.max_len)

        all_cols = df.columns.tolist()
        value_cols = self.cat_names + self.cont_names
        meta_cols = [col for col in all_cols if not col in value_cols]
        self.meta_df = df[meta_cols]

        if self.feats_first:
            return (
                tensor(df[self.cat_names].values).long(),
                tensor(df[self.cont_names].values).float(),
                TensorCategory(tgt),
            )
        else:
            return (
                tensor(df[self.cat_names].values).long().transpose(1, 0),
                tensor(df[self.cont_names].values).float().transpose(1, 0),
                TensorCategory(tgt),
            )

    def decodes(self, x):
        cats, conts, tgt = x
        if self.feats_first:
            cats_df = pd.DataFrame(cats.numpy(), columns=self.cat_names)
            conts_df = pd.DataFrame(conts.numpy(), columns=self.cont_names)
        else:
            cats_df = pd.DataFrame(cats.transpose(1, 0).numpy(), columns=self.cat_names)
            conts_df = pd.DataFrame(conts.transpose(1, 0).numpy(), columns=self.cont_names)

        df = pd.concat(
            [self.meta_df.reset_index(drop=True), cats_df, conts_df],
            axis="columns",
        ).reset_index(drop=True)

        return (df, tgt)

# Cell
class Pad_Seq(ItemTransform):
    def encodes(self, samples, pad_idx=-999, pad_fields=[0, 1], pad_first=False, backwards=False):
        "Function that collect `samples` and adds padding"
        self.pad_idx = pad_idx
        pad_fields = L(pad_fields)
        max_len_l = pad_fields.map(lambda f: max([len(s[f]) for s in samples]))
        if backwards: pad_first = not pad_first
        def _f(field_idx, x):
            if field_idx not in pad_fields: return x
            idx = pad_fields.items.index(field_idx) #TODO: remove items if L.index is fixed
            sl = slice(-len(x), sys.maxsize) if pad_first else slice(0, len(x))
            pad =  x.new_zeros((max_len_l[idx]-x.shape[0], x.shape[1]))+pad_idx
            x1 = torch.cat([pad, x] if pad_first else [x, pad], dim=0)
            if backwards: x1 = x1.flip(0)
            return retain_type(x1, x)
        return [tuple(map(lambda idxx: _f(*idxx), enumerate(s))) for s in samples]
    def decodes(self, t):
        pad_idx = self.pad_idx if hasattr(self,'pad_idx') else 1
        def _decode(o):
            def _f(tsr): return (tsr.shape[0] == 1) and (tsr.tolist()[0] == pad_idx)
            return  o[np.where([not _f(torch.unique(t)) for t in torch.unbind(o)])]
        return (_decode(t[0]), _decode(t[1]), t[2])

pad_seq=Pad_Seq()