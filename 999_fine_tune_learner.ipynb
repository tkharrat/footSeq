{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9682ceff-272a-4585-abf7-f37cf945c45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1935125/3341169811.py:4: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  from IPython.utils import traitlets as _traitlets\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.debugger import set_trace\n",
    "from IPython.utils import traitlets as _traitlets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e69ca32-1a84-4ded-a014-6cb6000e8c9f",
   "metadata": {},
   "source": [
    "<h1><center> Fine tune learner </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06aa88e-f669-408c-b202-4b42207e389a",
   "metadata": {},
   "source": [
    "In this notebook, we show how we can fine tune an already trained learner. The idea is to show a learner more training examples with a low learning rate to improve it without loosing the trained weights already obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6bd8a0-d7ee-4cf9-b902-27a780a4197a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os             : Linux-5.11.0-46-generic-x86_64-with-glibc2.31\n",
      "python         : 3.9.6\n",
      "tsai           : 0.2.25\n",
      "fastai         : 2.5.3\n",
      "fastcore       : 1.3.26\n",
      "torch          : 1.9.1\n",
      "n_cpus         : 16\n",
      "device         : cuda (NVIDIA GeForce GTX 1050 Ti)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import tempfile\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from random import sample\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fastcore.basics import *\n",
    "from fastcore.foundation import *\n",
    "from fastcore.xtras import load_pickle, save_pickle\n",
    "from progressbar import progressbar\n",
    "from tsai.all import *\n",
    "\n",
    "from footSeq.datastruct.core import *\n",
    "from footSeq.model.learner import *\n",
    "from footSeq.plots import *\n",
    "\n",
    "device = default_device()\n",
    "computer_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53240c0-ea06-4fb4-89ca-4dc33fa9f2ed",
   "metadata": {},
   "source": [
    "# Load a Trained learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e375f03-eba8-4963-80b8-d81e31ca295a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner loaded:\n",
      "path          = 'models/LSTM_FCN_bidir-True_layers-2_no_goal_prop-2_full_data'\n",
      "model_fname   = 'model.pth'\n",
      "learner_fname = 'learner.pkl'\n"
     ]
    }
   ],
   "source": [
    "model_name = \"LSTM_FCN_bidir-True_layers-2_no_goal_prop-2_full_data\"\n",
    "base_path = Path(\".\")\n",
    "\n",
    "learn = load_all(\n",
    "    path=base_path / \"models\" / model_name,\n",
    "    dls_fname=\"dls\",\n",
    "    model_fname=\"model\",\n",
    "    learner_fname=\"learner\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021202e1-1992-48d5-8b3f-01a94da0b902",
   "metadata": {},
   "source": [
    "# Predict one game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f765df8d-1e32-447c-8d17-2f91c40091ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from footSeq.config.mongo import mongo_init\n",
    "\n",
    "mongo_init(\"prod_atlas\")\n",
    "\n",
    "game_id = 2162758\n",
    "\n",
    "game_probs = learn.predict_game(game_id, save=True)\n",
    "\n",
    "game_probs.to_csv(\"/home/tarak/Downloads/action_values_\" + str(game_id) +\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155914bb-95d2-438c-b772-94a6059e1392",
   "metadata": {},
   "source": [
    "# Investigate Learner attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9978d6fa-aa91-4649-bf45-1832bb856b1a",
   "metadata": {},
   "source": [
    "This option is inspired from [This blog](https://www.geeksforgeeks.org/how-to-get-a-list-of-class-attributes-in-python/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a11922d-1dc8-480a-8112-d90888bb36be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('T_destination', ~T_destination)\n",
      "('arch', <class 'tsai.models.RNN_FCN.LSTM_FCN'>)\n",
      "('body', LSTM_FCN(\n",
      "  (rnn): LSTM(74, 100, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (rnn_dropout): Dropout(p=0.8, inplace=False)\n",
      "  (shuffle): Permute(dims=0, 2, 1)\n",
      "  (convblock1): ConvBlock(\n",
      "    (0): Conv1d(74, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (convblock2): ConvBlock(\n",
      "    (0): Conv1d(128, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (convblock3): ConvBlock(\n",
      "    (0): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (gap): GAP1d(\n",
      "    (gap): AdaptiveAvgPool1d(output_size=1)\n",
      "    (flatten): Flatten(full=False)\n",
      "  )\n",
      "  (concat): Concat(dim=1)\n",
      "  (fc): Linear(in_features=328, out_features=2, bias=True)\n",
      "))\n",
      "('c_in', 74)\n",
      "('c_out', 2)\n",
      "('cbs', [TrainEvalCallback, Recorder, ProgressCallback])\n",
      "('create_mbar', True)\n",
      "('dl', None)\n",
      "('dls', <fastai.data.core.DataLoaders object at 0x7fde783de1c0>)\n",
      "('dls_type', 'DataLoaders')\n",
      "('dump_patches', False)\n",
      "('epoch', 9)\n",
      "('final_record', [0.43088412284851074, 0.4629155099391937, 0.7726750373840332])\n",
      "('head', MultiEmbedding(\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (cat_embed): ModuleList(\n",
      "    (0): Embedding(8, 5)\n",
      "    (1): Embedding(6, 4)\n",
      "    (2): Embedding(5, 4)\n",
      "    (3): Embedding(8, 5)\n",
      "    (4): Embedding(3, 3)\n",
      "    (5): Embedding(3, 3)\n",
      "    (6): Embedding(3, 3)\n",
      "    (7): Embedding(35, 12)\n",
      "    (8): Embedding(15, 7)\n",
      "    (9): Embedding(7, 5)\n",
      "    (10): Embedding(3, 3)\n",
      "    (11): Embedding(3, 3)\n",
      "    (12): Embedding(5, 4)\n",
      "    (13): Embedding(4, 3)\n",
      "    (14): Embedding(5, 4)\n",
      "  )\n",
      "))\n",
      "('iter', 1564)\n",
      "('logger', <built-in function print>)\n",
      "('loss', None)\n",
      "('loss_func', FlattenedLoss of CrossEntropyLoss())\n",
      "('loss_grad', TensorBase(0.0473, device='cuda:0'))\n",
      "('lr', 0.001)\n",
      "('metrics', [<fastai.learner.AvgMetric object at 0x7fdc887e21f0>])\n",
      "('model', MixedSeqModel(\n",
      "  (head): MultiEmbedding(\n",
      "    (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "    (cat_embed): ModuleList(\n",
      "      (0): Embedding(8, 5)\n",
      "      (1): Embedding(6, 4)\n",
      "      (2): Embedding(5, 4)\n",
      "      (3): Embedding(8, 5)\n",
      "      (4): Embedding(3, 3)\n",
      "      (5): Embedding(3, 3)\n",
      "      (6): Embedding(3, 3)\n",
      "      (7): Embedding(35, 12)\n",
      "      (8): Embedding(15, 7)\n",
      "      (9): Embedding(7, 5)\n",
      "      (10): Embedding(3, 3)\n",
      "      (11): Embedding(3, 3)\n",
      "      (12): Embedding(5, 4)\n",
      "      (13): Embedding(4, 3)\n",
      "      (14): Embedding(5, 4)\n",
      "    )\n",
      "  )\n",
      "  (body): LSTM_FCN(\n",
      "    (rnn): LSTM(74, 100, num_layers=2, batch_first=True, bidirectional=True)\n",
      "    (rnn_dropout): Dropout(p=0.8, inplace=False)\n",
      "    (shuffle): Permute(dims=0, 2, 1)\n",
      "    (convblock1): ConvBlock(\n",
      "      (0): Conv1d(74, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (convblock2): ConvBlock(\n",
      "      (0): Conv1d(128, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (convblock3): ConvBlock(\n",
      "      (0): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (gap): GAP1d(\n",
      "      (gap): AdaptiveAvgPool1d(output_size=1)\n",
      "      (flatten): Flatten(full=False)\n",
      "    )\n",
      "    (concat): Concat(dim=1)\n",
      "    (fc): Linear(in_features=328, out_features=2, bias=True)\n",
      "  )\n",
      "))\n",
      "('model_dir', Path('models/LSTM_FCN_bidir-True_layers-2_no_goal_prop-2_full_data'))\n",
      "('moms', (0.95, 0.85, 0.95))\n",
      "('n_cont', 6)\n",
      "('n_epoch', 10)\n",
      "('n_iter', 1565)\n",
      "('n_loaders', 2)\n",
      "('opt', <fastai.optimizer.Optimizer object at 0x7fde783dec40>)\n",
      "('opt_func', <function Adam at 0x7fdceebc8430>)\n",
      "('path', Path('.'))\n",
      "('pct_train', 0.9999999999998362)\n",
      "('pred', None)\n",
      "('progress', ProgressCallback)\n",
      "('recorder', Recorder)\n",
      "('smooth_loss', TensorBase(0.4309))\n",
      "('splitter', <function trainable_params at 0x7fdd08c7c550>)\n",
      "('train_bn', True)\n",
      "('train_eval', TrainEvalCallback)\n",
      "('train_iter', 36490)\n",
      "('training', False)\n",
      "('wd', None)\n",
      "('wd_bn_bias', False)\n",
      "('x', None)\n",
      "('xb', (None,))\n",
      "('y', None)\n",
      "('yb', (None,))\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "# members of an object \n",
    "for i in inspect.getmembers(learn):\n",
    "      \n",
    "    # to remove private and protected\n",
    "    # functions\n",
    "    if not i[0].startswith('_'):\n",
    "          \n",
    "        # To remove other methods that\n",
    "        # doesnot start with a underscore\n",
    "        if not inspect.ismethod(i[1]): \n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc3d67a-8ccc-4521-9f46-1c325ed1f289",
   "metadata": {},
   "source": [
    "Now, we load all training files:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b328bb2-4e75-49ef-bec0-d0d1b78464ee",
   "metadata": {},
   "source": [
    "# Prepare data-loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91f5ed3-603d-4bfb-bb49-20a312f3a2a2",
   "metadata": {},
   "source": [
    "We will split our files into train/valid data-loaders. `Dataloaders` will be saved on the disk and will be re-used later eventually: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f054f47e-40cc-49a6-bb2f-3530fa3ced7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = Path(\"./data\")\n",
    "files_list_path = metadata_path / \"file_list.pkl\"\n",
    "model_path = Path(\"./models/LSTM_FCN_bidir-True_layers-2_no_goal_prop-2_fine_tuned\")\n",
    "\n",
    "all_files = L(load_pickle(files_list_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150bf015-d9df-446c-9053-55d767ac1581",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-23 10:18:30 - working on chunk:13/21 !\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "chunk_size = int(len(all_files) / 20)\n",
    "chunks = chunker(all_files, chunk_size)\n",
    "n_chunks = len(list(chunks))\n",
    "chunk = 0\n",
    "\n",
    "for chunk_files in chunker(all_files, chunk_size):\n",
    "    splits_files = RandomSplitter(seed=42)(chunk_files)\n",
    "    chunk +=1\n",
    "    if chunk == 13:\n",
    "        logging.info(f\"working on chunk:{chunk}/{n_chunks} !\")\n",
    "        new_train_dl = learn.dls.test_dl(chunk_files[splits_files[0]], with_labels=True, shuffle=True, drop_last=True)\n",
    "        new_valid_dl = learn.dls.test_dl(chunk_files[splits_files[1]], with_labels=True)\n",
    "        torch.save(new_train_dl, model_path / f\"train_dls-{chunk}-{n_chunks}.pth\")\n",
    "        torch.save(new_valid_dl, model_path / f\"valid_dls-{chunk}-{n_chunks}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a926bb-9345-430a-bee4-21563a510387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
